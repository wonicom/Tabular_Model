# -*- coding: utf-8 -*-
"""visualization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OoSFPEwty9VQBGaS6k_CDd-cTzmsHOvB
"""

import numpy as np
import pandas as pd
import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import make_classification
from keras.models import Sequential
from keras.layers import LSTM, Dense
from sklearn.svm import SVC

from google.colab import drive
drive.mount('/content/drive')

path = '/content/drive/MyDrive/gas_sensor_drift_final/Dataset'
files = os.listdir(path)

dataframes = []

for file in files :
  if file.endswith('.dat') :
    df = pd.read_csv(os.path.join(path, file), sep='\s+', header=None)
    dataframes.append(df)

def extract_value(x):
      parts = str(x).split(':')
      if len(parts) == 2:
          return float(parts[1])

for files in dataframes:
    for col in files.columns[1:]:
        files[col] = files[col].apply(lambda x: extract_value(x))

for i in range(0,10) :
  dataframes[i].rename(columns={0:'Target'},inplace = True)

for j in range(0,10) :

  map={1:0,2:1,3:2,4:3,5:4,6:5}
  dataframes[j]["Target"] = dataframes[j]["Target"].map(map)

!pip install tabgan

class Display:
    def plot_result(self, db_trained, p_data, p_gen, epoch):
        # Plotting Decision Boundary
        plt.figure(figsize=(8, 6))
        plt.plot(db_trained, label='Decision Boundary', alpha=0.5)
        plt.xlabel('Data')
        plt.ylabel('Probability')
        plt.title(f'Decision Boundary after Epoch {epoch}')
        plt.legend()
        plt.show()

        # Plotting Real and Generated Distributions
        plt.figure(figsize=(8, 6))
        plt.hist(p_data, bins=30, density=True, alpha=0.5, label='Real Data Distribution')
        plt.hist(p_gen, bins=30, density=True, alpha=0.5, label='Generated Data Distribution')
        plt.xlabel('Value')
        plt.ylabel('Density')
        plt.title(f'Real and Generated Distributions after Epoch {epoch}')
        plt.legend()
        plt.show()

from scipy.stats import ks_2samp
from tabgan.sampler import OriginalGenerator, GANGenerator, ForestDiffusionGenerator

# Loop through the steps (i values)
for i in range(1):
    train = dataframes[i].iloc[:, 1:129]
    target = dataframes[i].iloc[:, 0]
    test = dataframes[i + 1].iloc[:, 1:129]

    train_df = pd.DataFrame(train)
    target_df = pd.DataFrame(target)
    test_df = pd.DataFrame(test)

    train_df = train_df.fillna(train_df.median())
    target_df = target_df.fillna(target_df.median())
    test_df = test_df.fillna(test_df.median())

    # Generate data after each i iteration
    new_train, new_target = GANGenerator(gen_x_times=1.1, cat_cols=None,
            bot_filter_quantile=0.001, top_filter_quantile=0.999, is_post_process=True,
            adversarial_model_params={
                "metrics": "AUC", "max_depth": 2, "max_bin": 100,
                "learning_rate": 0.02, "random_state": 42, "n_estimators": 100,
            }, pregeneration_frac=2, only_generated_data=False,
            gen_params = {"batch_size": 500, "patience": 25, "epochs" : 40,}).generate_data_pipe(train_df, target_df,
                                            test_df, deep_copy=True, only_adversarial=False, use_adversarial=True)

import seaborn as sns
import matplotlib.pyplot as plt

# Assuming 'new_train' contains the generated data
# Plot density plots for original and generated data
for column in train_df.columns:
    plt.figure(figsize=(8, 4))

    # Original Data Density Plot
    sns.kdeplot(train_df[column], label='Original')

    # Generated Data Density Plot
    sns.kdeplot(new_train[column], label='Generated')

    plt.xlabel(column)
    plt.ylabel('Density')
    plt.title(f'Probability Distribution of {column} Before and After Generation')
    plt.legend()
    plt.show()

import pandas as pd
from tabgan.sampler import GANGenerator
import matplotlib.pyplot as plt

original_data_sizes = []
generated_data_sizes = []
combined_data_sizes = []

for i in range(1, len(dataframes)):  # Loop through iterations
    train = dataframes[i - 1].iloc[:, 1:129]
    target = dataframes[i - 1].iloc[:, 0]
    test = dataframes[i].iloc[:, 1:129]

    train_df = pd.DataFrame(train)
    target_df = pd.DataFrame(target)
    test_df = pd.DataFrame(test)

    train_df = train_df.fillna(train_df.median())
    target_df = target_df.fillna(target_df.median())
    test_df = test_df.fillna(test_df.median())

    # Get lengths of original train data before generation
    original_length_before = len(train_df.values.flatten())
    original_data_sizes.append(original_length_before)

    # Instantiate GANGenerator
    generator = GANGenerator(gen_x_times=1.1, cat_cols=None,
                             bot_filter_quantile=0.001, top_filter_quantile=0.999, is_post_process=True,
                             adversarial_model_params={
                                 "metrics": "AUC", "max_depth": 2, "max_bin": 100,
                                 "learning_rate": 0.02, "random_state": 42, "n_estimators": 100,
                             }, pregeneration_frac=2, only_generated_data=False,
                             gen_params={"batch_size": 500, "patience": 25, "epochs": 40})

    # Generate data using the generator
    new_train, new_target = generator.generate_data_pipe(train_df, target_df, test_df,
                                                         deep_copy=True, only_adversarial=False, use_adversarial=True)

    # Get lengths of augmented train data after generation
    augmented_length_after = len(new_train.values.flatten())
    generated_data_sizes.append(augmented_length_after)

    # Calculate total data size after augmentation
    total_length_after = original_length_before + augmented_length_after
    combined_data_sizes.append(total_length_after)

# Plotting the comparison of data sizes
iterations = range(1, len(dataframes))
plt.figure(figsize=(10, 6))
plt.bar(iterations, original_data_sizes, width=0.25, label='Original Data', align='center', color='skyblue')
plt.bar(iterations, combined_data_sizes, width=-0.25, label='Generator Data', align='edge', color='orange')
plt.xlabel('Iterations')
plt.ylabel('Data Size')
plt.title('Comparison of Original, Generated, and Combined Data Sizes After GAN')
plt.legend()
plt.show()

from scipy.stats import ks_2samp
from tabgan.sampler import OriginalGenerator, GANGenerator, ForestDiffusionGenerator

# Loop through the steps (i values)
for i in range(1):
    train = dataframes[i].iloc[:, 1:129]
    target = dataframes[i].iloc[:, 0]
    test = dataframes[i + 1].iloc[:, 1:129]

    train_df = pd.DataFrame(train)
    target_df = pd.DataFrame(target)
    test_df = pd.DataFrame(test)

    train_df = train_df.fillna(train_df.median())
    target_df = target_df.fillna(target_df.median())
    test_df = test_df.fillna(test_df.median())

    # Generate data after each i iteration
    new_train, new_target = GANGenerator(gen_x_times=1.1, cat_cols=None,
            bot_filter_quantile=0.001, top_filter_quantile=0.999, is_post_process=True,
            adversarial_model_params={
                "metrics": "AUC", "max_depth": 2, "max_bin": 100,
                "learning_rate": 0.02, "random_state": 42, "n_estimators": 100,
            }, pregeneration_frac=2, only_generated_data=False,
            gen_params = {"batch_size": 500, "patience": 25, "epochs" : 40,}).generate_data_pipe(train_df, target_df,
                                            test_df, deep_copy=True, only_adversarial=False, use_adversarial=True)

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming 'new_train' contains the generated data
for column in train_df.columns:
    fig, ax1 = plt.subplots(figsize=(8, 6))

    if train_df[column].dtype == 'object':
        # Bar plot for categorical data
        sns.countplot(x=column, data=train_df, alpha=0.5, label='Original', ax=ax1)
        sns.countplot(x=column, data=new_train, alpha=0.5, label='Generated', ax=ax1)

        ax1.set_xlabel(column)
        ax1.set_ylabel('Count')
        ax1.set_title(f'Bar Plot of {column} Before and After Generation')
        ax1.legend()
        ax1.tick_params(axis='x', rotation=45)  # Rotate x-axis labels for better visibility

    else:
        # Histogram for continuous data
        ax1.hist(train_df[column], bins=50, alpha=0.5, label='Original', density=True)
        ax1.hist(new_train[column], bins=50, alpha=0.5, label='Generated', density=True)

        ax1.set_xlabel(column)
        ax1.set_ylabel('Density')
        ax1.set_title(f'Probability Distribution of {column} Before and After Generation')
        ax1.legend()

        # Creating a twin axis for line plot
        ax2 = ax1.twinx()
        # Example line plot (you can replace this with your specific line plot)
        ax2.plot(train_df[column].value_counts().sort_index(), color='red', label='Original Line')
        ax2.plot(new_train[column].value_counts().sort_index(), color='blue', label='Generated Line')
        ax2.set_ylabel('Line Plot Label')
        ax2.legend(loc='upper right')

    plt.show()

from scipy.stats import ks_2samp
from tabgan.sampler import OriginalGenerator, GANGenerator, ForestDiffusionGenerator

# Loop through the steps (i values)
for i in range(1):
    train = dataframes[i].iloc[:, 1:129]
    target = dataframes[i].iloc[:, 0]
    test = dataframes[i + 1].iloc[:, 1:129]

    train_df = pd.DataFrame(train)
    target_df = pd.DataFrame(target)
    test_df = pd.DataFrame(test)

    train_df = train_df.fillna(train_df.median())
    target_df = target_df.fillna(target_df.median())
    test_df = test_df.fillna(test_df.median())

    # Generate data after each i iteration
    new_train, new_target = GANGenerator(gen_x_times=1.1, cat_cols=None,
            bot_filter_quantile=0.001, top_filter_quantile=0.999, is_post_process=True,
            adversarial_model_params={
                "metrics": "AUC", "max_depth": 2, "max_bin": 100,
                "learning_rate": 0.02, "random_state": 42, "n_estimators": 100,
            }, pregeneration_frac=2, only_generated_data=False,
            gen_params = {"batch_size": 500, "patience": 25, "epochs" : 40,}).generate_data_pipe(train_df, target_df,
                                            test_df, deep_copy=True, only_adversarial=False, use_adversarial=True)

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming 'new_train' contains the generated data
# Visualizing probability distributions of generated data
for column in new_train.columns:
    plt.figure(figsize=(8, 6))

    # Plotting KDE plots for each feature (column) in the generated data
    sns.kdeplot(new_train[column], label='Generated Data', shade=True)

    # Plotting original data's distribution for comparison (optional)
    sns.kdeplot(train_df[column], label='Original Data', shade=True)

    plt.xlabel(column)
    plt.ylabel('Density')
    plt.title(f'Probability Distribution of {column} in Generated Data')
    plt.legend()
    plt.show()

