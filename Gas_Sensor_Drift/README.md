# 다중 네트워크 모델 앙상블을 이용한 가스센서 드리프트의 보상

## Sensor drift란?
Sensor drift는 주변 환경의 온도, 습도, 압력뿐만 아니라 센서 물질의 노화 및 피독 효과(외부 오염, 비가역적 조합 포함)와 같은 일부 요소의 간섭을 의미하여, 이로 인해 간섭 신호에 관여하는 센서 입력 신호가 발생한다. 외부 완경은 간섭신호를 지속적으로 증가시키며, 이는 데이터 품질 및 획득 정확도의 점진적인 하락을 초래한다. 참 값과의 차이가 커지며, 출력값으로 가스 종류를 판단하기 어렵다.

## Sensor software compensation란?
센서 소프트웨어 보상은 이러한 불완전한 센서 출력을 보정하고 정확한 값으로 변환하기 위해 사용된다. 이를 위해 소프트웨어 알고리즘을 사용하여 센서에서 나오는 신호를 해석하고 보상하는 작업을 수행한다. 이러한 알고리즘은 센서의 특성과 성능을 모델링하고 이해하여 센서 출력을 보정하며, 시간이 지남에 따라 센서의 특성이 변하는 경우에도 이를 고려하여 보상을 수행할 수 있다.

## Datasets in Experiment
실험에 사용된 데이터는 UCI데이터셋에서 얻었다. 저자들은 가스 센서 드리프트 보정을 위해 16개의 금속 산화물 가스 센서 배열을 사용하여 3년동안 시뮬레이션을 수행했다. 궁극적으로 그들은 여섯 가지 다른 휘발성 유기 화합물의 다양한 농도에서 13,910개의 측정을 얻었다. 시뮬레이션은 실제 드리프트만 유도하도록 엄격하게 통제되었다. 각 샘플에는 클래스 레이블과 128차원 특징 벡터가 포함되어 있으며, 이러한 특징들은 최대 저항 변화와 지수 이동 평균의 차이를 사용하여 센서 응답에서 추출되었다. 이 특징들은 정적 상태와 동적 상태 모두에서 가스 검출 응답을 설명한다. 또한 적절한 훈련 데이터를 얻기 위해, 저자들은 이 데이터를 시간에 따라 결합하여 10개의 배치를 형성했다. 10개의 배치 간 샘플의 분포 불일치를 더 잘 관찰하기 위해, 각 배치의 응탑에 대한 산포도를 그림으로 나타냈다. 10개의 배치 산포토는 샘플 수집 기간 동안 드리프트가 존재함을 보여주며, 첫 두 개의 주성분 분포가 각 배치마다 매우 다르다.<br>

![image](https://github.com/wonicom/Tabular_Model/assets/123945441/abd8bc8d-1028-406d-8952-6fe96d7bbc73)
![image](https://github.com/wonicom/Tabular_Model/assets/123945441/6d0a6275-3704-4e9d-ad60-1916c19ed480)
![image](https://github.com/wonicom/Tabular_Model/assets/123945441/53448797-d1b5-469d-9eb8-1b86ece50add)
![image](https://github.com/wonicom/Tabular_Model/assets/123945441/259a0114-1a5d-4f8b-9e27-a94a2d20c87e)
![image](https://github.com/wonicom/Tabular_Model/assets/123945441/5fedb494-6b8d-455c-9ae6-159665aba1e9)

데이터셋 드리프트를 확인하기 위해 SVM 모델을 사용하여 정확도를 평가했다. Batch1을 훈련 세트로 설정하고 Batch2부터 Batch10까지 각각을 테스트 세트로 설정하여 평가를 진행했다. 표에 나와 있는 바와 같이, 실험 배치에 따라 분류기의 성능이 달라지며, 이는 시간이 지남에 따라 변화가 있음을 나타낸다.(표에서 Batch1에서 Batch10으로 데이터 수집이 진행되는 동안) 분류기의 성능이 저하되는 것은 센서 드리프트의 지표로 적용할 수 있다. 이 실험은 센서에서 수집된 데이터가 드리프트를 겪는지 여부를 검증하며, 드리프트가 분류기의 성능에 부정적인 영향을 미친다는 것을 보여준다.<br>

<img width="500" alt="image" src="https://github.com/wonicom/Tabular_Model/assets/123945441/b4f55b92-1c3a-4063-872c-700dcfbdc0c2">

## Ensemble Models in Experiment
### A. Data Generation
딥러닝에서는 구조화된 데이터가 과적합 문제를 겪고 전체적인 성능이 낮아지는 경향이 있어서, 구조화된 데이터 분석에서 딥러닝의 활용이 상대적으로 적은 연구 결과를 보인다. 그래서 우리는 구조화된 데이터의 소수 클래스를 증강하기 위해 CT-GAN을 사용해. 비록 전통적이고 효과적인 오버샘플링 기법들이 있긴 하지만, 딥러닝의 장점을 활용하려는 것이다. CT-GAN은 연속형 변수와 범주형 변수로 구성된 구조화된 데이터를 생성할 때 발생하는 문제를 해결하기 위해 설계된 GAN 기반 아키텍처다. 특히 표형 데이터를 합성하는 데 특화되어 있다. CT-GAN을 사용했을 때, 사용하지 않았을 때(Table2)와 비교해서 성능이 크게 향상된 걸 알 수 있다.<br>

<img width="500" alt="image" src="https://github.com/wonicom/Tabular_Model/assets/123945441/35df5b4a-09c6-4707-abbf-ce212b9695af">

<br>

### Base Classifier
다음 두 가지 데이터 설정을 고려한다. Setting01에서는 최신 배치 데이터를 훈련 세트로 선택한다. 이 결정은 센서 드리프트로 인해 발생하는 테스트 세트와 훈련 세트 간의 차이를 최소화하기 위해서이다. Setting02에서는 다른 접근 방식을 취한다. 최신 배치만 선택하는 대신, 최신 배치 이전의 모든 데이터를 훈련 세트로 사용한다.

<img width="500" alt="image" src="https://github.com/wonicom/Tabular_Model/assets/123945441/79a75202-c295-4dec-9937-e3a1820e2b1e">
<img width="500" alt="image" src="https://github.com/wonicom/Tabular_Model/assets/123945441/c590e7b5-9721-48d7-98c5-89d316008c47">
<img width="500" alt="image" src="https://github.com/wonicom/Tabular_Model/assets/123945441/d617c57d-2db9-4f4b-89af-b91a8cd7c53e">

### Ensemble Classifier
TSL 앙상블 모델은 TabNet, SVM, 그리고 LSTM을 기본 분류기로 채택한다. 이 모델들의 하이퍼파라미터 설정은 앞서 언급한 구성과 일치한다. 모델의 구조는 그림에 나타난 대로이다.
<img width="528" alt="image" src="https://github.com/wonicom/Tabular_Model/assets/123945441/2de928a1-2920-4c5c-83fa-ce16d16037cd">
앙상블 학습은 여러 개의 개별 학습기를 훈련시키고 그들의 예측을 결합하여 목표 함수를 학습하는 방법들의 모음을 말한다. 투표 분류기 모델은 개별 머신 러닝 분류기라고 하는 여러 독립된 모델을 결합하여 하나의 모델로 만드는 앙상블 학습 방법이다. 이는 개별 알고리즘보다는 메타 분류기 알고리즘으로 간주된다. 앙상블 학습 접근법은 예측 모델의 성능을 향상시킬 수 있어 유용하다. 앙상블 학습은 분산과 편향을 감소시켜[18] 궁극적으로 예측 정확도를 개선한다. 투표 분류기는 여러 모델로부터 학습하고, 선택될 가능성에 따라 출력을 예측한다. 우리는 서로 다른 투표 방법을 사용하여 이들을 비교했다.

<img width="500" alt="image" src="https://github.com/wonicom/Tabular_Model/assets/123945441/e2d0e285-8ff0-4fe1-9a06-53be91828981">

투표에는 세 가지 방법이 있다: 소프트 투표, 하드 투표, 가중 투표이다. 소프트 투표는 약한 학습기들의 예측 확률 값을 평균이나 가중 합을 사용한다. 개별 학습기의 예측보다는 예측 확률 값의 평균이 중요하며, 최종 예측은 가장 높은 확률을 가진 클래스를 선택하여 결정된다. 반면 하드 투표는 약한 학습기들의 예측을 다수결로 기반으로 예측을 수행한다. 가중 투표는 각 학습기에 다른 가중치를 할당할 수 있으며, 단순한 평균이 아니라 확률 값의 가중 합을 사용한다.<br>
<br>
표에서는 weighted voting가 가장 높은 정확도를 달성했다는 것을 관찰할 수 있다. test voting로 batch 4, 5, 7을 사용했을 때, soft voting의 분류 정확도는 하드 투표보다 낮다. batch 10을 test set로 사용했을 때, soft voting의 분류 정확도는 74.86%이고, hard voting는 72.89%이며, weighted voting는 80.47%이다. 각 voting 방법의 평균 성능을 고려할 때, 소프트 투표는 84.27%의 정확도를 달성하였고, hard voting는 83.96%의 정확도를 달성했으며, weighted voting는 88.19%의 가장 높은 정확도를 보여주었다. 이러한 결과는 weighted voting가 다른 두 voting 방법보다 우수한 성능을 발휘하여 전체적인 예측 정확도를 향상시키는 데 효과적임을 나타낸다.

## Conclusion
이 실험에서는 변동하는 가스 농도 수준에 관계없이 어려운 가스 센서 드리프트 문제를 해결하기 위해 개선된 TSL 앙상블을 제안했습니다. 우리의 접근 방식은 특히 TabNet, SVM, 그리고 LSTM으로 구성된 여러 분류기의 장점을 활용하여 견고하고 정확한 가스 판별 솔루션을 만들어냅니다. 세 곳에서 진행된 세 가지 연도 동안 공개된 데이터셋을 사용한 포괄적인 실험을 통해, 우리는 TSL 앙상이 단일 모델 분류기 및 1D 분류기 앙상블보다 우수함을 입증했습니다. 결론적으로, TSL 앙상블은 가스 판별 정확도를 향상시키며, 다양하고 효율적인 해결책을 제공하며, 넓은 적용 범위와 더 나은 발전 가능성을 제공합니다.

